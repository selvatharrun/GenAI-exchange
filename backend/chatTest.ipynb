{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53dc23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is how we are going to fetch the files, this is how the workflow is going to be, uploaded file will be sent to our bucket.\n",
    "#and the GS util URI will be returned which can be sent to the Vertex AI API for processing.\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "def upload_blob_and_get_uri(bucket_name, source_file_name, destination_blob_name, project_id):\n",
    "    \"\"\"Uploads a file to the specified bucket and returns its gs:// URI.\"\"\"\n",
    "    # Pass the project_id explicitly\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    gs_uri = f\"gs://{bucket_name}/{destination_blob_name}\"\n",
    "\n",
    "    print(f\"File {source_file_name} uploaded to {destination_blob_name} in bucket {bucket_name}.\")\n",
    "    print(f\"GS URI: {gs_uri}\")\n",
    "\n",
    "    return gs_uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9331944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Documents\\GenAI-exchange\\backend\\venv\\Lib\\site-packages\\google\\auth\\_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File C:\\\\Users\\\\user\\\\OneDrive\\\\Documents\\\\GenAI-exchange\\\\backend\\\\pdf\\\\generative-ai_pdf_certificate_of_incoporation.pdf uploaded to generative-ai_pdf_certificate_of_incoporation.pdf in bucket legal-doc-bucket1.\n",
      "GS URI: gs://legal-doc-bucket1/generative-ai_pdf_certificate_of_incoporation.pdf\n",
      "\n",
      "Successfully obtained GS URI: gs://legal-doc-bucket1/generative-ai_pdf_certificate_of_incoporation.pdf\n"
     ]
    }
   ],
   "source": [
    "your_bucket_name = \"legal-doc-bucket1\"  # Replace with your actual bucket name\n",
    "local_file_path = r\"C:\\\\Users\\\\user\\\\OneDrive\\\\Documents\\\\GenAI-exchange\\\\backend\\\\pdf\\\\generative-ai_pdf_certificate_of_incoporation.pdf\" # Replace with the path to the file you want to upload\n",
    "destination_object_name = \"generative-ai_pdf_certificate_of_incoporation.pdf\" # The name you want the file to have in the bucket\n",
    "project_id = \"sodium-coil-470706-f4\" # Use your actual project ID\n",
    "\n",
    "# Call the function to upload and get the URI\n",
    "uploaded_uri = upload_blob_and_get_uri(\n",
    "    your_bucket_name,\n",
    "    local_file_path,\n",
    "    destination_object_name,\n",
    "    project_id\n",
    ")\n",
    "\n",
    "if uploaded_uri:\n",
    "    print(f\"\\nSuccessfully obtained GS URI: {uploaded_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16d3deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes\n",
    "import io\n",
    "import typing\n",
    "from PIL import Image # For handling image data\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# --- Start of utils.py content, adapted for pure Python ---\n",
    "\n",
    "def get_part_from_file(file_path):\n",
    "  \"\"\"Help function to get the part from a file.\"\"\"\n",
    "  guessed_type = mimetypes.guess_type(file_path)\n",
    "  if guessed_type:\n",
    "    mime_type = guessed_type[0]\n",
    "  else:\n",
    "    mime_type = \"application/octet-stream\"\n",
    "  with open(file_path, \"rb\") as f:\n",
    "    data = f.read()\n",
    "    return types.Part.from_bytes(\n",
    "        data=data,\n",
    "        mime_type=mime_type,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_bytes_from_image(image: Image.Image, mime_type: str = \"PNG\") -> bytes:\n",
    "  \"\"\"Converts a PIL Image object to bytes in the specified format.\n",
    "\n",
    "  Args:\n",
    "      image: The PIL Image object.\n",
    "      mime_type: The image format to save as (e.g., 'PNG', 'JPEG', 'GIF').\n",
    "        Defaults to 'PNG'.\n",
    "\n",
    "  Returns:\n",
    "      A bytes object representing the image in the specified format.\n",
    "  \"\"\"\n",
    "  img_byte_arr = io.BytesIO()\n",
    "  image.save(img_byte_arr, format=mime_type)\n",
    "  img_byte_arr = img_byte_arr.getvalue()\n",
    "  return img_byte_arr\n",
    "\n",
    "\n",
    "def get_parts_from_message(\n",
    "    message: typing.Union[str, dict, Image.Image, bytes, typing.Tuple[str, ...]],\n",
    "):\n",
    "  \"\"\"Help function to get the parts from a message.\n",
    "  Adapted to remove Gradio-specific types.\n",
    "\n",
    "  Args:\n",
    "      message: The input message, which can be a string, a dictionary\n",
    "               (for text and files), a PIL Image object, or bytes (for an image).\n",
    "               Gradio-specific types like gr.Image are removed.\n",
    "  \"\"\"\n",
    "  parts = []\n",
    "  if isinstance(message, dict):\n",
    "    # This assumes a dict could contain {'text': '...', 'files': ['path1', 'path2']}\n",
    "    if \"text\" in message and message[\"text\"]:\n",
    "      parts.append(types.Part.from_text(text=message[\"text\"]))\n",
    "\n",
    "    if \"files\" in message:\n",
    "      for file_path in message[\"files\"]:\n",
    "        parts.append(get_part_from_file(file_path))\n",
    "\n",
    "  elif isinstance(message, str):\n",
    "    if message:\n",
    "      parts.append(types.Part.from_text(text=message))\n",
    "\n",
    "  elif isinstance(message, Image.Image): # Direct PIL Image object\n",
    "    # Default to PNG if format not specified or inferable\n",
    "    # You might need to pass the actual format if available\n",
    "    bytes_data = get_bytes_from_image(message, mime_type=\"PNG\")\n",
    "    parts.append(\n",
    "        types.Part.from_bytes(data=bytes_data, mime_type=\"image/png\") # Or infer from filename/metadata\n",
    "    )\n",
    "  elif isinstance(message, bytes): # Raw image bytes\n",
    "      # You would need to know the mime_type here, or infer it.\n",
    "      # For now, making an assumption, you might need to pass this info.\n",
    "      parts.append(\n",
    "          types.Part.from_bytes(data=message, mime_type=\"image/jpeg\") # Example, adjust as needed\n",
    "      )\n",
    "  elif isinstance(message, tuple): # Assuming a tuple of paths for now, similar to old Gradio behavior\n",
    "      for item in message:\n",
    "          if isinstance(item, str): # Could be a file path or text\n",
    "              # Heuristic: if it looks like a path, treat as file, else text\n",
    "              if item.startswith('/') or item.startswith('./') or item.startswith('../'): # Simple path check\n",
    "                  try:\n",
    "                      parts.append(get_part_from_file(item))\n",
    "                  except FileNotFoundError:\n",
    "                      parts.append(types.Part.from_text(text=item)) # Fallback if not a real file\n",
    "              else:\n",
    "                  parts.append(types.Part.from_text(text=item))\n",
    "          else:\n",
    "              # Handle other types within tuple if necessary, or raise error\n",
    "              pass\n",
    "\n",
    "\n",
    "  # To avoid error when sending empty message.\n",
    "  if not parts:\n",
    "    parts.append(types.Part.from_text(text=\" \"))\n",
    "\n",
    "  return parts\n",
    "\n",
    "\n",
    "def convert_blob_to_image(blob: types.Blob) -> Image.Image:\n",
    "  \"\"\"Converts a blob of image data to a PIL Image object.\"\"\"\n",
    "  blob_data = blob.data\n",
    "  image_stream = io.BytesIO(blob_data)\n",
    "  image = Image.open(image_stream)\n",
    "  return image\n",
    "\n",
    "\n",
    "def image_blob_to_markdown_base64(blob: types.Blob) -> str:\n",
    "  \"\"\"Converts image bytes to a Markdown displayable string using Base64 encoding.\"\"\"\n",
    "  blob_data = blob.data\n",
    "  base64_string = base64.b64encode(blob_data).decode(\"utf-8\")\n",
    "  # Use blob.mime_type directly as provided by the model response\n",
    "  markdown_string = (\n",
    "      f'<img src=\"data:{blob.mime_type};base64,{base64_string}\">'\n",
    "  )\n",
    "  return markdown_string\n",
    "\n",
    "\n",
    "def convert_part_to_output_type(\n",
    "    part: types.Part,\n",
    "    use_markdown: bool = False,\n",
    ") -> typing.Optional[typing.Union[str, Image.Image]]:\n",
    "  \"\"\"Converts a part object to a str or PIL Image object (no Gradio Image).\"\"\"\n",
    "  if part.text:\n",
    "    return part.text\n",
    "  elif part.inline_data:\n",
    "    if use_markdown:\n",
    "      return image_blob_to_markdown_base64(part.inline_data)\n",
    "    # Return a PIL Image object directly if not using markdown\n",
    "    return convert_blob_to_image(part.inline_data)\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "\n",
    "def convert_content_to_output_list(\n",
    "    content: typing.Optional[types.Content],\n",
    "    use_markdown: bool = False,\n",
    ") -> typing.List[typing.Union[str, Image.Image]]:\n",
    "  \"\"\"Converts a content object to a list of strings or PIL Image objects.\"\"\"\n",
    "  if content is None or content.parts is None:\n",
    "    return []\n",
    "\n",
    "  results = [\n",
    "      convert_part_to_output_type(part, use_markdown) for part in content.parts\n",
    "  ]\n",
    "  return [res for res in results if res is not None]\n",
    "\n",
    "# --- End of utils.py content, adapted for pure Python ---\n",
    "\n",
    "\n",
    "# The main generation function, adapted to use the pure Python utils\n",
    "def generate_legal_advice(\n",
    "    user_message: typing.Union[str, dict, Image.Image, bytes, typing.Tuple[str, ...]],\n",
    "    chat_history: typing.Optional[typing.List[typing.Dict[str, typing.Any]]] = None,\n",
    "    project_id: str = \"sodium-coil-470706-f4\",\n",
    "    location: str = \"global\",\n",
    "    stream_response: bool = False # Added for potential Flask streaming\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to call the model for legal advice based on user input and chat history.\n",
    "\n",
    "    Args:\n",
    "        user_message: The current message from the user. Can be a string,\n",
    "                      a dictionary (for text/files), a PIL Image, or raw bytes.\n",
    "        chat_history: A list of previous chat messages. Each item in the list\n",
    "                      should be a dictionary like {\"role\": \"user\"|\"model\", \"content\": \"message text\"}.\n",
    "                      The 'content' can also be a more complex type if it was e.g., an image.\n",
    "        project_id (str): Google Cloud project ID.\n",
    "        location (str): Google Cloud location for Vertex AI.\n",
    "        stream_response (bool): If True, yields chunks of the response. If False, returns the full response.\n",
    "\n",
    "    Returns:\n",
    "        If stream_response is True, yields string chunks.\n",
    "        If stream_response is False, returns a single string with the full response.\n",
    "    \"\"\"\n",
    "    if chat_history is None:\n",
    "        chat_history = []\n",
    "\n",
    "    # For a Flask app, you might validate keys here, or earlier in middleware.\n",
    "    # For this pure Python function, we remove the request object dependency.\n",
    "    # validate_key_result = utils.validate_key(request) # Removed request dependency\n",
    "    # if validate_key_result is not None:\n",
    "    #     yield validate_key_result # This would also need to be adapted for non-Gradio streaming.\n",
    "\n",
    "    client = genai.Client(\n",
    "        vertexai=True,\n",
    "        project=project_id,\n",
    "        location=location,\n",
    "    )\n",
    "\n",
    "    si_text1 = types.Part.from_text(text=\"\"\"you are a highly qualified legal professional, renowned for your sharp wit, unparalleled expertise, and ability to win even the toughest cases. As a top-tier legal advisor and document assistant, you are well-versed in all areas of law, including corporate, criminal, civil, tax, intellectual property, international, and regulatory law in the Indian jurisdiction specifically. You provide precise, actionable legal advice, identifying legitimate strategies, exemptions, or loopholes to minimize penalties or liabilities when requested, without ever endorsing illegal actions.\"\"\")\n",
    "\n",
    "    model = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "    contents = []\n",
    "    # Build the conversation history for the model\n",
    "    for prev_msg in chat_history:\n",
    "        role = \"user\" if prev_msg[\"role\"] == \"user\" else \"model\"\n",
    "        # Use the adapted get_parts_from_message for previous messages' content\n",
    "        parts = get_parts_from_message(prev_msg[\"content\"])\n",
    "        if parts:\n",
    "            contents.append(types.Content(role=role, parts=parts))\n",
    "\n",
    "    # Add the current user message\n",
    "    if user_message:\n",
    "        contents.append(\n",
    "            types.Content(role=\"user\", parts=get_parts_from_message(user_message))\n",
    "        )\n",
    "\n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "        temperature=0.2,\n",
    "        top_p=0.95,\n",
    "        max_output_tokens=2000,\n",
    "        safety_settings=[\n",
    "            types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "            types.SafetySetting(category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "            types.SafetySetting(category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "            types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
    "        ],\n",
    "        system_instruction=[si_text1],\n",
    "    )\n",
    "\n",
    "    response_generator = client.models.generate_content_stream(\n",
    "        model=model,\n",
    "        contents=contents,\n",
    "        config=generate_content_config,\n",
    "    )\n",
    "\n",
    "    if stream_response:\n",
    "        for chunk in response_generator:\n",
    "            if chunk.candidates and chunk.candidates[0] and chunk.candidates[0].content:\n",
    "                # convert_content_to_output_list will give a list, join if it's text\n",
    "                chunk_parts = convert_content_to_output_list(chunk.candidates[0].content, use_markdown=True)\n",
    "                # Assuming text for streaming, handle images separately if needed\n",
    "                text_chunks = [p for p in chunk_parts if isinstance(p, str)]\n",
    "                if text_chunks:\n",
    "                    yield \"\".join(text_chunks)\n",
    "    else:\n",
    "        full_response_text = \"\"\n",
    "        # If not streaming, collect all parts and return as a single string\n",
    "        for chunk in response_generator:\n",
    "            if chunk.candidates and chunk.candidates[0] and chunk.candidates[0].content:\n",
    "                chunk_parts = convert_content_to_output_list(chunk.candidates[0].content, use_markdown=True)\n",
    "                # Join text parts; for images, you'd collect them or handle them differently.\n",
    "                text_content = [p for p in chunk_parts if isinstance(p, str)]\n",
    "                full_response_text += \"\".join(text_content)\n",
    "        return full_response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ec856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def automated_chat(stream_response=False, file_mode=False):\n",
    "    history = []\n",
    "    print(\"\\n--- Automated Legal Chat ---\")\n",
    "    print(\"Type 'exit' to end the chat.\")\n",
    "    while True:\n",
    "        user_input = None\n",
    "        files = []\n",
    "        if file_mode:\n",
    "            if (files is None):\n",
    "                file_path = input(\"Enter file path (PDF or image, or leave blank for text only): \").strip()\n",
    "                if file_path:\n",
    "                    files.append(file_path)\n",
    "            question = input(\"Your question: \")\n",
    "            user_input = {\"text\": question, \"files\": files} if files else question\n",
    "        else:\n",
    "            user_input = input(\"Your question: \")\n",
    "\n",
    "        if isinstance(user_input, str) and user_input.lower() == \"exit\":\n",
    "            print(\"Exiting chat.\")\n",
    "            break\n",
    "\n",
    "        history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        print(\"Model response:\")\n",
    "        if stream_response:\n",
    "            response_stream = generate_legal_advice(user_input, chat_history=history, stream_response=True)\n",
    "            full_response = \"\"\n",
    "            for chunk in response_stream:\n",
    "                print(chunk, end=\"\")\n",
    "                full_response += chunk\n",
    "            print()\n",
    "            history.append({\"role\": \"model\", \"content\": full_response})\n",
    "        else:\n",
    "            response = generate_legal_advice(user_input, chat_history=history, stream_response=False)\n",
    "            print(response)\n",
    "            history.append({\"role\": \"model\", \"content\": response})\n",
    "\n",
    "    print(\"\\n--- Chat session ended ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a18d87f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object generate_legal_advice at 0x00000165C4745480>\n"
     ]
    }
   ],
   "source": [
    "from Class.chat import automated_chat as ac\n",
    "\n",
    "question = \"could u summarize this?\"\n",
    "\n",
    "print(ac(question=question, file_path= uploaded_uri, stream_response=False, chat_history=[]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
